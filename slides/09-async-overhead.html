<!-- 4. OVERHEAD OF ASYNC/AWAIT & PROMISES -->
<section id="async-overhead">
  <section class="section-header">
    <h2>Overhead of async/await &amp; Promises</h2>
    <p>Convenience has a cost</p>
  </section>

  <section>
    <h3>What async/await Actually Does</h3>
    <pre><code class="language-javascript">// This innocent-looking code:
async function getUser(id) {
  const user = await db.findById(id)
  return user
}

// Creates under the hood:
// 1. A Promise object
// 2. A microtask for resolution
// 3. Captures the async context (AsyncLocalStorage, etc.)
// 4. Suspends and resumes the function execution
// 5. Another microtask for the awaited promise</code></pre>
    <div class="insight">
      Each <code>await</code> creates at minimum 1 Promise + 1-2 microtask queue entries.
      On hot paths running millions of times, this adds up fast.
    </div>
  </section>

  <section>
    <h3>The Cost Chain</h3>
    <pre><code class="language-javascript">// Every layer of async adds overhead
async function getUser(id) {             // Promise #1
  const row = await queryDb(id)          // Promise #2
  return formatUser(row)
}

async function queryDb(id) {             // Promise #3
  const conn = await pool.acquire()      // Promise #4
  try {
    return await conn.query('...', [id]) // Promise #5
  } finally {
    pool.release(conn)
  }
}

// One "simple" DB query = 5+ Promises allocated
// At 10,000 req/s = 50,000 Promises/s = GC pressure</code></pre>
  </section>

  <section>
    <h3>Callback vs async/await</h3>
    <table class="benchmark">
      <thead>
        <tr><th>Pattern</th><th>Time</th><th>vs callback</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>sync function</td>
          <td>1.0 ns</td>
          <td class="speedup">baseline</td>
        </tr>
        <tr>
          <td>callback (sync fire)</td>
          <td>2.3 ns</td>
          <td class="speedup">~1x</td>
        </tr>
        <tr>
          <td>async/await</td>
          <td>338 ns</td>
          <td><strong>145x slower</strong></td>
        </tr>
        <tr>
          <td>new Promise(resolve => ...)</td>
          <td>311 ns</td>
          <td><strong>133x slower</strong></td>
        </tr>
      </tbody>
    </table>
    <p class="small">Apple M3 Pro / Node.js 25.3.0 — .gc('inner') enabled</p>
    <div class="insight">
      Callbacks fire synchronously with zero allocation. <code>async/await</code> always creates
      a Promise + microtask — even when the result is already available.
    </div>
  </section>

  <section>
    <h3>Sync Fast Path</h3>
    <pre><code class="language-javascript">// If the value is already available, avoid async entirely
function getFromCache(id) {
  const cached = cache.get(id)
  if (cached !== undefined) {
    return cached  // No Promise, no microtask, instant
  }
  // Only go async when actually needed
  return getFromCacheAsync(id)
}

async function getFromCacheAsync(id) {
  const value = await db.get(id)
  cache.set(id, value)
  return value
}</code></pre>
    <div class="insight">
      Split your hot paths into sync and async variants.
      When the common case is synchronous (cache hit), you skip all async overhead.
    </div>
  </section>

  <section>
    <h3>The Async Return Pattern</h3>
    <pre><code class="language-javascript">// You have a function that SOMETIMES needs to be async
async function resolve(key) {
  const cached = cache.get(key)
  if (cached) return cached       // Already have it! But...
  return await fetchRemote(key)   // ...this needs async
}

// The caller always pays the async cost:
const value = await resolve(key)  // Promise allocated even for cache hit</code></pre>
  </section>

  <section>
    <h3>The Async Return Pattern</h3>
    <pre><code class="language-javascript">// Return a discriminated result instead
function resolve(key) {
  const cached = cache.get(key)
  return cached
    ? { async: false, value: cached }
    : { async: true,  value: fetchRemote(key) }
}

// Caller can fast-path the sync case:
const result = resolve(key)
const value = result.async
  ? await result.value    // Only await when truly async
  : result.value          // Zero-cost sync path</code></pre>
  </section>

  <section>
    <h3>Async Return Pattern — Real World</h3>
    <pre><code class="language-javascript">// Processing a stream of messages — most are cache hits
function processMessage(msg) {
  const result = resolve(msg.key)

  if (result.async) {
    // Queue for async processing
    return result.value.then(value => handle(msg, value))
  }

  // Hot path: immediate, zero-allocation handling
  handle(msg, result.value)
}

// At 100k messages/sec with 95% cache hit rate:
// - Without pattern: 100k Promises/sec
// - With pattern:      5k Promises/sec (95% fewer)</code></pre>
    <div class="insight">
      At 100k msg/s with 95% cache hits: 95k avoid Promises entirely.
      The sync path is a plain function call — no allocation, no microtask, no GC.
    </div>
  </section>

  <section>
    <h3>Async Return Pattern — Benchmarks</h3>
    <table class="benchmark">
      <thead>
        <tr><th>Scenario</th><th>async function</th><th>Async return</th><th>Speedup</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>1000 lookups, 100% hit</td>
          <td>70.8 µs</td>
          <td>9.4 µs</td>
          <td class="speedup">7.6x</td>
        </tr>
        <tr>
          <td>1000 lookups, 95% hit</td>
          <td>75.5 µs</td>
          <td>14.6 µs</td>
          <td class="speedup">5.2x</td>
        </tr>
        <tr>
          <td>1000 lookups, 50% hit</td>
          <td>101.9 µs</td>
          <td>61.9 µs</td>
          <td class="speedup">1.6x</td>
        </tr>
        <tr>
          <td>GC pressure (95% hit)</td>
          <td>406 KB</td>
          <td>5 KB</td>
          <td class="speedup">81x less</td>
        </tr>
      </tbody>
    </table>
    <p class="small">Apple M3 Pro / Node.js 25.3.0</p>
    <div class="insight">
      At 95% cache hit rate: 5x faster, 81x less GC pressure.
      The higher the hit rate, the bigger the win.
    </div>
  </section>
</section>
