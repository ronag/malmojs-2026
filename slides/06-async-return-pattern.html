<!-- 5. THE ASYNC RETURN PATTERN -->
<section id="async-return-pattern">
  <section class="section-header">
    <h2>The Async Return Pattern</h2>
    <p><code>return { async: boolean, value: any }</code></p>
  </section>

  <section>
    <h3>The Problem</h3>
    <pre><code class="language-javascript">// You have a function that SOMETIMES needs to be async
async function resolve(key) {
  const cached = cache.get(key)
  if (cached) return cached       // Already have it! But...
  return await fetchRemote(key)   // ...this needs async
}

// The caller always pays the async cost:
const value = await resolve(key)  // Promise allocated even for cache hit</code></pre>
  </section>

  <section>
    <h3>The Solution</h3>
    <pre><code class="language-javascript">// Return a discriminated result instead
function resolve(key) {
  const cached = cache.get(key)
  if (cached) {
    return { async: false, value: cached }
  }
  return { async: true, value: fetchRemote(key) }
}

// Caller can fast-path the sync case:
const result = resolve(key)
const value = result.async
  ? await result.value    // Only await when truly async
  : result.value          // Zero-cost sync path</code></pre>
  </section>

  <section>
    <h3>Real-World Application</h3>
    <pre><code class="language-javascript">// Processing a stream of messages — most are cache hits
function processMessage(msg) {
  const result = resolve(msg.key)

  if (result.async) {
    // Queue for async processing
    return result.value.then(value => handle(msg, value))
  }

  // Hot path: immediate, zero-allocation handling
  handle(msg, result.value)
}

// At 100k messages/sec with 95% cache hit rate:
// - Without pattern: 100k Promises/sec
// - With pattern:      5k Promises/sec (95% fewer)</code></pre>
    <div class="insight">
      At 100k msg/s with 95% cache hits: 95k avoid Promises entirely.
      The sync path is a plain function call — no allocation, no microtask, no GC.
    </div>
  </section>

  <section>
    <h3>Benchmarks: Cache Lookup</h3>
    <table class="benchmark">
      <thead>
        <tr><th>Scenario</th><th>async function</th><th>Async return</th><th>Speedup</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>1000 lookups, 100% hit</td>
          <td>70.8 µs</td>
          <td>9.4 µs</td>
          <td class="speedup">7.6x</td>
        </tr>
        <tr>
          <td>1000 lookups, 95% hit</td>
          <td>75.5 µs</td>
          <td>14.6 µs</td>
          <td class="speedup">5.2x</td>
        </tr>
        <tr>
          <td>1000 lookups, 50% hit</td>
          <td>101.9 µs</td>
          <td>61.9 µs</td>
          <td class="speedup">1.6x</td>
        </tr>
        <tr>
          <td>GC pressure (95% hit)</td>
          <td>406 KB</td>
          <td>5 KB</td>
          <td class="speedup">81x less</td>
        </tr>
      </tbody>
    </table>
    <p class="small">Apple M3 Pro / Node.js 25.3.0</p>
    <div class="insight">
      At 95% cache hit rate: 5x faster, 81x less GC pressure.
      The higher the hit rate, the bigger the win.
    </div>
  </section>
</section>
