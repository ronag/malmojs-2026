<!-- 14. UV THREAD POOL CONFIGURATION -->
<section id="uv-threadpool">
  <section class="section-header">
    <h2>UV Thread Pool Configuration</h2>
    <p>The hidden bottleneck</p>
  </section>

  <section>
    <h3>What Uses the Thread Pool?</h3>
    <pre><code class="language-javascript">// All of these compete for the SAME thread pool:
fs.readFile(path, callback)         // File I/O
fs.stat(path, callback)             // File metadata
crypto.pbkdf2(pass, salt, cb)       // Crypto
dns.lookup(host, callback)          // DNS resolution
zlib.deflate(buffer, callback)      // Compression

// Default pool size: 4 threads
// If all 4 are busy with crypto, your DNS lookups queue up!
// If all 4 are doing fs reads, your HTTP requests stall!</code></pre>
  </section>

  <section>
    <h3>Configuring the Pool</h3>
    <pre><code class="language-bash"># Set BEFORE requiring anything; must be in environment
UV_THREADPOOL_SIZE=16 node server.js</code></pre>
    <div style="display:flex;gap:12px;margin-top:14px">
      <div style="flex:1;background:#1a1a1a;border-radius:6px;padding:10px 14px;border-left:3px solid #569cd6">
        <div style="color:#569cd6;font-weight:bold;font-size:0.8em;margin-bottom:4px">I/O heavy</div>
        <div style="color:#999;font-size:0.7em">16–64 threads<br>File serving, database proxy</div>
      </div>
      <div style="flex:1;background:#1a1a1a;border-radius:6px;padding:10px 14px;border-left:3px solid #c586c0">
        <div style="color:#c586c0;font-weight:bold;font-size:0.8em;margin-bottom:4px">CPU heavy (crypto)</div>
        <div style="color:#999;font-size:0.7em">8–16 threads<br>More threads ≠ more throughput</div>
      </div>
      <div style="flex:1;background:#1a1a1a;border-radius:6px;padding:10px 14px;border-left:3px solid #e7ad52">
        <div style="color:#e7ad52;font-weight:bold;font-size:0.8em;margin-bottom:4px">Mixed workload</div>
        <div style="color:#999;font-size:0.7em">16–32 threads<br>Benchmark YOUR workload</div>
      </div>
    </div>
    <div class="warning" style="margin-top:14px">
      Default is <strong>4 threads</strong>, almost certainly too low for production.<br>
      The pool is shared across all Worker threads in the same process; more workers = more contention.
    </div>
  </section>

  <section>
    <h3>Gotchas</h3>
    <div style="display:flex;gap:12px">
      <div style="flex:1;background:#1a1a1a;border-radius:6px;padding:12px 14px;border-left:3px solid #ff5252">
        <div style="color:#ff5252;font-weight:bold;font-size:0.8em;margin-bottom:6px">Must set early</div>
        <div style="color:#999;font-size:0.7em">
          <code style="color:#bbb">UV_THREADPOOL_SIZE</code> is read once, when libuv initializes the pool.
          Setting it after any I/O has started has no effect.
        </div>
      </div>
      <div style="flex:1;background:#1a1a1a;border-radius:6px;padding:12px 14px;border-left:3px solid #ff5252">
        <div style="color:#ff5252;font-weight:bold;font-size:0.8em;margin-bottom:6px">More ≠ better</div>
        <div style="color:#999;font-size:0.7em">
          More threads = more memory + context switching overhead.
          Pure fs on SSD can regress with too many threads. Max: 1024.
        </div>
      </div>
      <div style="flex:1;background:#1a1a1a;border-radius:6px;padding:12px 14px;border-left:3px solid #ff5252">
        <div style="color:#ff5252;font-weight:bold;font-size:0.8em;margin-bottom:6px">Shared across Workers</div>
        <div style="color:#999;font-size:0.7em">
          All Worker threads in the same process share one pool.
          4 workers × 4 pool threads = each worker effectively gets ~1 thread.
        </div>
      </div>
    </div>
  </section>

  <section>
    <h3>Pool Size vs Throughput</h3>
    <div style="font-size:0.7em;color:#999;margin-bottom:8px;text-align:center">
      <a href="https://github.com/nodejs/node/pull/61533" style="color:#42affa">nodejs/node#61533</a>, auto-sizes UV_THREADPOOL_SIZE to available parallelism
    </div>
    <!-- 16 vCPU machine: auto-sizing 4 → 16 threads -->
    <div style="font-size:0.65em;color:#888;margin-bottom:4px">16 vCPU / 32GB, autocannon 100 connections, 30s per route</div>
    <table class="benchmark">
      <thead>
        <tr><th>Workload</th><th>4 threads (baseline)</th><th>16 threads (PR)</th><th>Change</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>/crypto</td>
          <td>122K req/s</td>
          <td>467K req/s</td>
          <td class="speedup">+281%</td>
        </tr>
        <tr>
          <td>/mixed (fs + crypto)</td>
          <td>651K req/s</td>
          <td>1,230K req/s</td>
          <td class="speedup">+89%</td>
        </tr>
        <tr>
          <td>/fs</td>
          <td>1,830K req/s</td>
          <td>1,549K req/s</td>
          <td style="color:#ff5252">−15%</td>
        </tr>
      </tbody>
    </table>
    <!-- 4 vCPU: same pool size = no change -->
    <div style="display:flex;gap:10px;margin-top:10px">
      <div style="flex:1;background:#1a1a1a;border-radius:6px;padding:10px 14px;border-left:3px solid #e7ad52">
        <div style="color:#e7ad52;font-weight:bold;font-size:0.8em;margin-bottom:4px">4 vCPU, no change</div>
        <div style="color:#999;font-size:0.7em">Pool stays at 4 threads → identical performance</div>
      </div>
      <div style="flex:1;background:#1a1a1a;border-radius:6px;padding:10px 14px;border-left:3px solid #ff5252">
        <div style="color:#ff5252;font-weight:bold;font-size:0.8em;margin-bottom:4px">fs regression</div>
        <div style="color:#999;font-size:0.7em">More threads = more contention on same FDs. SSD is already fast enough.</div>
      </div>
    </div>
    <p class="small">AMD EPYC-Rome @ 2.0GHz, benchmarks by @RafaelGSS</p>
    <div class="insight">
      Auto-sizing gives +281% on crypto-heavy workloads for free.
      Pure fs on SSD sees slight regression; more threads add scheduling overhead, not speed.
    </div>
  </section>

  <section>
    <h3>Coordinating with Scheduler</h3>
    <pre><code class="language-javascript">import { Scheduler } from '@nxtedition/scheduler'

// Know your thread pool size
const poolSize = parseInt(process.env.UV_THREADPOOL_SIZE || '4', 10)

// Share it across workers
const sharedState = Scheduler.makeSharedState(poolSize)

// Each worker respects the global limit
const ioScheduler = new Scheduler(sharedState)

// Prioritize user-facing I/O over background tasks
async function handleRequest(req) {
  return ioScheduler.run(() => fs.readFile(path), 'high')
}

async function backgroundIndex() {
  return ioScheduler.run(() => fs.readFile(path), 'low')
}</code></pre>
  </section>
</section>
